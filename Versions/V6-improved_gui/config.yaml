# Model Configuration
model:
  name: "gpt-4o-mini"  # default model
  configs:
    gpt-4o:
      context_window: 128000
      max_output_tokens: 16384
    gpt-4o-mini:
      context_window: 128000
      max_output_tokens: 16384

# Analysis Configuration
analysis:
  token_safety_margin: 0.75
  perform_final_analysis: true
  max_tokens_per_chunk: 8000
  token_estimate_ratio: 4
  default_context_window: 4096
  default_max_output: 1024

# Default paths
paths:
  project_dir: "./Sample_Directories"  # Change this line
  output_dir: "./Sample_Outputs"  # Add this line
  output_file: "./Sample_Outputs/code_analysis_report.md"

# Logging Configuration
logging:
  level: "DEBUG"
  colors:
    debug: "cyan"
    info: "green"
    warning: "yellow"
    error: "red"
    critical: "red,bg_white"